<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.12.12"/><meta name="theme-color" content="#5155c0"/><link rel="icon" href="/favicon-32x32.png?v=541c764f1369e4797ac9eab5ff6db701" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=541c764f1369e4797ac9eab5ff6db701"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=541c764f1369e4797ac9eab5ff6db701"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div style="margin:50px 0px 20px 10px"><div class="container"><div class="justify-content-md-center row"><div class="col-sm-2"><img src="profile.jpg" class="rounded-circle"/></div><div class="col-sm-6"><div>Ryutaro Asahara</div><div>M2, The Department of Informatics, The University of Electro-Communications.</div><div><a href="https://www.inaba.aix.uec.ac.jp/" target="_blank" rel="noopener noreferrer">Inaba Lab.</a></div><div>Email: ryu1104.as[at]gmail.com</div><br/><div><a href="https://github.com/Ryutaro-A" target="_blank" rel="noopener noreferrer">Github</a></div><div><a href="https://twitter.com/Ryu_pro_m" target="_blank" rel="noopener noreferrer">Twitter</a></div></div></div></div><div style="margin:50px 0px 20px 10px"><div class="container"><div class="justify-content-md-center row"><div class="col-sm-2"><h3>Education</h3></div><div class="col-sm-6"><b></b></div></div><div style="margin:20px 0px 20px 10px"><div class="justify-content-md-center row"><div class="col-sm-2">2022/04 -</div><div class="col-sm-6"><b>Master&#x27;s degree, Department of Informatics, The University of Electro-Communications, Japan</b></div></div></div><div style="margin:20px 0px 20px 10px"><div class="justify-content-md-center row"><div class="col-sm-2">2018/04 - 2022/03</div><div class="col-sm-6"><b>Bachelor&#x27;s degree, Department of Computer and Information Science, Seikei University, Japan</b></div></div></div></div></div><div style="margin:50px 0px 20px 10px"><div class="container"><div class="justify-content-md-center row"><div class="col-sm-2"><h3>Papers</h3></div><div class="col-sm-6"><b></b></div></div><div style="margin:20px 0px 20px 10px"><div class="justify-content-md-center row"><div class="col-sm-2"><a href="https://paclic2023.github.io/" target="_blank" rel="noopener noreferrer">The 37th Pacific Asia Conference on Language, Information and Computation (PACLIC 37)</a></div><div class="col-sm-6"><a href="https://paclic2023.github.io/" target="_blank" rel="noopener noreferrer">SumRec: A Framework for Recommendation using Open-Domain Dialogue</a><br/><font size="2">Ryutaro Asahara, Masaki Takahashi, Chiho Iwahashi, Michimasa Inaba</font><br/><b>Abstract</b><br/><font size="2">Chat dialogues contain considerable useful in- formation about a speaker’s interests, prefer- ences, and experiences. Thus, knowledge from open-domain chat dialogue can be used to personalize various systems and offer recom- mendations for advanced information. This study proposed a novel framework SumRec for recommending information from open-domain chat dialogue. The study also examined the framework using ChatRec, a newly constructed dataset for training and evaluation 1. To ex- tract the speaker and item characteristics, the SumRec framework employs a large language model (LLM) to generate a summary of the speaker information from a dialogue and to rec- ommend information about an item according to the type of user. The speaker and item infor- mation are then input into a score estimation model, generating a recommendation score. Ex- perimental results show that the SumRec frame- work provides better recommendations than the baseline method of using dialogues and item descriptions in their original form.</font></div></div></div><div style="margin:20px 0px 20px 10px"><div class="justify-content-md-center row"><div class="col-sm-2"><a href="https://jsai-slud.github.io/sig-slud/99th-sig.html" target="_blank" rel="noopener noreferrer">第14回対話システムシンポジウム</a></div><div class="col-sm-6"><a href="https://jsai-slud.github.io/sig-slud/99th-sig.html" target="_blank" rel="noopener noreferrer">Multimodal Dialogue System using Third Party Persona</a><br/><font size="2">Ryutaro Asahara, Hiroki Onozeki, Kazuma Akiyama, Ryuichi Uehara, Zhiyang Qi, Takumasa Kaneko, Tomoya Higuchi, Michimasa Inaba</font><br/><b>Abstract</b><br/><font size="2">This paper describes a dialogue system we developed for the Situation Track of the Dialogue System Live Competition 6. The system was designed to engage in multimodal dialogue about planning a welcome party with a user. We utilized ChatGPT for generating responses and determining motions, and we crafted a specific prompt for ChatGPT. The prompt included the persona of Dr. Kobayashi, a third party who is not part of the dialogue but is the guest of honor at the party, to ensure consistent discussion about him. The prompt was also structured to produce dialogue act tags with each utterance, enabling the system to display appropriate motions based on the context. Additionally, by inserting filler words when an utterance with a negative dialogue act tag is produced, we conveyed the system’s compromise or discomfort regarding any disagreement with the user.</font></div></div></div></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/about/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-ee171eb25fcf0aafc268.js\"],\"component---src-pages-about-js\":[\"/component---src-pages-about-js-b0861b03524f4ff57bd0.js\"],\"component---src-pages-header-js\":[],\"component---src-pages-image-js\":[],\"component---src-pages-index-js\":[\"/component---src-pages-index-js-8cb8d0c8bae2f3de0040.js\"],\"component---src-pages-publications-js\":[\"/component---src-pages-publications-js-bddf67723ff297390ed3.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="3ed90b6abfff30deb79d";</script><script src="/webpack-runtime-a5b18dfbf20087d7c8a4.js" async></script><script src="/framework-adc840d619fba6d1d9cd.js" async></script><script src="/app-ee171eb25fcf0aafc268.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>